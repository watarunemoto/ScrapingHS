import csv
import time
from urllib.parse import urlparse, parse_qs

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# ===== è¨­å®š =====
AREA_CODE = "13"  # æ±äº¬éƒ½ã®ã‚¨ãƒªã‚¢ã‚³ãƒ¼ãƒ‰
BASE_LIST_URL = f"https://school.js88.com/scl_h/ichiran/list?area={AREA_CODE}"
OUTPUT_CSV = "school_info.csv"

# ===== SeleniumåˆæœŸåŒ– =====
options = webdriver.ChromeOptions()
options.add_argument("--headless")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
wait = WebDriverWait(driver, 10)

# ===== å­¦æ ¡ä¸€è¦§ãƒšãƒ¼ã‚¸ã®å‡¦ç† =====
print("ğŸ“¥ å­¦æ ¡ä¸€è¦§ã‚’å–å¾—ä¸­...")
driver.get(BASE_LIST_URL)
time.sleep(2)  # ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ã‚’å¾…æ©Ÿ

# å„é«˜æ ¡ã®è©³ç´°ãƒšãƒ¼ã‚¸ã¸ã®ãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
school_links = set()
try:
    links = driver.find_elements(By.XPATH, '//a[contains(@href, "/scl_h/") and contains(@href, "220")]')
    for link in links:
        href = link.get_attribute("href")
        if href and "/scl_h/" in href:
            school_links.add(href.split("?")[0])
except Exception as e:
    print("é«˜æ ¡ãƒªãƒ³ã‚¯ã®å–å¾—ã«å¤±æ•—:", e)

print(f"âœ… {len(school_links)} ä»¶ã®é«˜æ ¡ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")

# ===== å„é«˜æ ¡ãƒšãƒ¼ã‚¸ã§ã®æƒ…å ±æŠ½å‡º =====
results = []
for url in sorted(school_links):
    print(f"ğŸ” å‡¦ç†ä¸­: {url}")
    driver.get(url)
    time.sleep(1)

    school_id = url.rstrip("/").split("/")[-1]

    try:
        school_name = wait.until(EC.presence_of_element_located((By.TAG_NAME, "h1"))).text.strip()
    except:
        school_name = ""

    try:
        address_full = wait.until(EC.presence_of_element_located((By.TAG_NAME, "address"))).text.strip()
        if "ã€’" in address_full:
            zip_code = address_full.split()[0].replace("ã€’", "")
            address = address_full.replace(f"ã€’{zip_code}", "").strip()
        else:
            zip_code = ""
            address = address_full
    except:
        zip_code = ""
        address = ""

    try:
        homepage_raw = wait.until(
            EC.presence_of_element_located((By.XPATH, '//dt[text()="ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸"]/following-sibling::dd[1]/a'))
        ).get_attribute("href")

        parsed = urlparse(homepage_raw)
        query = parse_qs(parsed.query)
        homepage = query.get("scl_url", [homepage_raw])[0]
    except:
        homepage = ""

    results.append([school_id, school_name, url, zip_code, address, homepage])

# ===== CSVæ›¸ãå‡ºã—ï¼ˆBOMä»˜ãUTF-8ï¼‰=====
with open(OUTPUT_CSV, "w", newline="", encoding="utf-8-sig") as f:
    writer = csv.writer(f)
    writer.writerow(["ID", "å­¦æ ¡å", "JS88_URL", "éƒµä¾¿ç•ªå·", "ä½æ‰€", "é«˜æ ¡ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸"])
    writer.writerows(results)

print(f"\nâœ… å®Œäº†ã—ã¾ã—ãŸã€‚{OUTPUT_CSV} ã« {len(results)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãå‡ºã—ã¾ã—ãŸã€‚")

driver.quit()
